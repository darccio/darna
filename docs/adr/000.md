# Building a Go atomic commit validator with transitive dependency checking

A Go CLI tool/pre-commit hook that validates atomic commits requires three core capabilities: parsing staged Go files for symbol definitions and usages, building a transitive dependency graph across packages, and detecting when staged code depends on unstaged/untracked changes that prevent the commit from being self-contained. **The implementation centers on `golang.org/x/tools/go/packages` for type-aware analysis combined with git commands for staging detection.**

**Key atomicity principle**: Staged files can depend on other staged files (no violation) or on already-committed files (no violation), but cannot depend on unstaged or untracked changes (violation). This ensures the commit is self-contained and will build successfully on checkout.

Integration with git hooks is straightforward—the tool simply exits 0 on success and non-zero on failure, with no special interface required. The primary complexity lies in accurately resolving cross-package symbol references and walking transitive dependencies.

## Architectural Decisions

The following table summarizes the key architectural choices and their rationale:

| Aspect | Decision | Rationale |
|--------|----------|-----------|
| **Package loading** | `golang.org/x/tools/go/packages` | Modern API with full type information; handles Go modules correctly |
| **Symbol resolution** | `types.Info.Defs` + `types.Info.Uses` | Built into type checker, cross-package aware, accurate |
| **Git integration** | Shell out to `git` commands | Simpler and more reliable than go-git for hooks; avoids library versioning issues |
| **Staged content** | `git show :path` | Correctly handles partial staging (file with both staged and unstaged changes) |
| **Call graph depth** | Type-based (no SSA) | Sufficient for symbol dependencies, significantly faster than SSA analysis |
| **Dependency direction** | Bidirectional edges | Allows both forward dependency traversal and reverse ("who depends on me") queries |
| **Method tracking** | Explicit receiver notation | Distinguishes package functions from methods in symbol IDs (`pkg.Type.Method`) |
| **Path handling** | Absolute internally, relative for display | More robust for working directory changes, consistent with git output |
| **Hook interface** | Standard exit codes | Exit 0 for success, non-zero for failure—no special integration needed |

## Implementation Architecture

The implementation is organized into focused packages with clear separation of concerns:

```
darna/
├── cmd/darna/                    # CLI entry point and user interaction
│   └── main.go                   # Flag parsing, violation display, exit codes
├── internal/
│   ├── analyzer/                 # Go package loading and symbol extraction
│   │   ├── analyzer.go           # packages.Load() wrapper, symbol collection
│   │   └── analyzer_test.go
│   ├── git/                      # Git repository state queries
│   │   ├── git.go                # Staged files, unstaged changes, file status
│   │   └── git_test.go
│   ├── graph/                    # Symbol dependency graph construction
│   │   ├── graph.go              # Graph building, transitive traversal
│   │   └── graph_test.go
│   └── validator/                # Core validation orchestration
│       ├── validator.go          # Atomic commit validation logic
│       ├── validator_test.go
│       ├── validator_e2e_test.go # E2E tests (1,148 lines)
│       └── testdata/project/     # Test fixtures with controlled dependencies
├── bin/darna                     # Compiled binary (7.1 MB)
├── go.mod                        # Go 1.24.0, golang.org/x/tools dependency
├── Makefile                      # Build, test, lint targets
└── .golangci.yml                 # Linter configuration
```

### Component Responsibilities

**`cmd/darna/main.go`** - User-facing CLI interface
- Accepts flags: `-v` (verbose), `-dir` (working directory, defaults to current)
- Calls `validator.ValidateAtomicCommit()` with specified working directory
- Groups violations by missing file for clarity
- Provides actionable suggestions (`git add <file>`) for remediation
- Returns exit code 1 on violations, 0 on success (git hook compatible)

**`internal/analyzer`** - Package loading and symbol extraction
- `LoadPackages(dir, overlay, patterns)` - Uses `golang.org/x/tools/go/packages` with full type information mode; accepts an optional `overlay map[string][]byte` for partial staging support
- `CollectSymbols(pkg)` - Extracts symbols defined and used within a package
- `ObjectKind(obj)` - Categorizes symbols as func, type, var, or const
- Filters to package-level definitions (skips non-package-scope items like local variables)
- Identifies external symbol references vs. internal package symbols

**`internal/git`** - Git repository state queries
- `GetStagedFiles()` - Returns files in the staging area (added, copied, modified, renamed)
- `GetUnstagedModified()` - Returns files with unstaged modifications
- `GetAllFileStatus()` - Complete file status using porcelain format with null separators
- `FilterGoFiles(files)` - Filters file list to `.go` files only
- `GetStagedContent(path)` - Reads staged version of a file (supports partial staging)
- All functions shell out to `git` commands for maximum reliability

**`internal/graph`** - Dependency graph construction and analysis
- Maintains symbol definitions, file-to-symbols mapping, and bidirectional dependency edges
- `AnalyzePackage(pkg)` - Two-pass AST analysis:
  - Pass 1: Register all symbol definitions from `TypesInfo.Defs`
  - Pass 2: Walk function bodies to find usages from `TypesInfo.Uses`
- `AddDependency(from, to)` - Adds both forward and reverse dependency edges
- `TransitiveDeps(startID)` - DFS to find all symbols a given symbol depends on
- `TransitiveDependents(targetID)` - DFS to find all symbols that depend on a given symbol
- Tracks methods separately with receiver notation for accurate dependency tracking

**`internal/validator`** - Core validation orchestration
- `ValidateAtomicCommit(workDir)` - Main validation entry point
- Coordinates git file status, package loading, graph building, and atomicity checking
- Builds `packages.Config.Overlay` for partially-staged (`MM`) files using `git show :path`, so analysis reflects staged content rather than working tree
- Identifies violations where staged code depends on unstaged changes
- Returns structured violation information for display

### Data Flow

```
Git Repository
    ↓ (git status --porcelain -z)
internal/git → File status (staged vs unstaged)
    ↓
internal/analyzer → Load packages with types
    ↓ (packages.Load with full type info)
internal/graph → Build dependency graph
    ↓ (TypesInfo.Defs + Uses, AST walk)
internal/validator → Check atomicity
    ↓ (transitive dependency analysis)
cmd/darna → Display violations, exit code
```

## Go Static Analysis Fundamentals for Symbol Tracking

The `golang.org/x/tools/go/packages` package is the modern, recommended API for loading Go packages with full type information. Unlike raw AST parsing, it resolves imports, performs type checking, and provides the `types.Info` struct essential for cross-package symbol resolution.

### Loading Packages with Complete Type Information

Package loading requires careful configuration of the `LoadMode` flags to obtain all necessary information. The implementation uses:

- `NeedName` - Package name and import path
- `NeedFiles` - List of file paths in the package
- `NeedSyntax` - Parsed AST (`[]*ast.File`)
- `NeedTypes` - Type-checked package (`*types.Package`)
- `NeedTypesInfo` - Detailed type information including `Defs` and `Uses` maps
- `NeedImports` - Imported packages
- `NeedDeps` - All transitive package dependencies

For atomic commit validation, `NeedTypesInfo` (which provides the `Defs` and `Uses` maps) and `NeedDeps` (to analyze cross-package references) are critical. Each loaded package then contains:

- `pkg.Syntax` - Parsed AST files
- `pkg.Types` - Type-checked package information
- `pkg.TypesInfo` - Detailed type information including symbol definition and usage maps
- `pkg.Fset` - Position information (`token.FileSet`) for error reporting and file location tracking

### Distinguishing Symbol Definitions from Usages

The `types.Info` struct contains two critical maps that are fundamental to building the dependency graph:

- **`Defs`** maps identifiers to objects they **define** (function declarations, type definitions, variable declarations, constants)
- **`Uses`** maps identifiers to objects they **reference** (function calls, type usage, variable references)

This distinction is essential for constructing accurate dependency relationships. When analyzing a package:

1. Iterate through `TypesInfo.Defs` to find all symbols defined at package scope
2. Filter out non-package-level definitions (local variables, function parameters)
3. Create symbol IDs using the pattern `obj.Pkg().Path() + "." + obj.Name()`
4. Iterate through `TypesInfo.Uses` to find all external symbol references
5. Filter to symbols from other packages (`obj.Pkg() != pkg.Types`)
6. Build dependency edges between the using symbol and used symbol

Every `types.Object` carries its defining package via `obj.Pkg()` and its source position via `obj.Pos()`, which can be converted to filename and line number using the `token.FileSet`. This positional information is critical for mapping symbols back to their defining files.

## Building the Symbol Dependency Graph

The dependency graph maps symbols to their dependencies and tracks which file defines each symbol. This enables the core validation: checking whether all symbols a staged file depends on are either staged or already committed.

### Graph Data Structures

The dependency graph maintains four key mappings:

**Symbol** - Represents a package-level definition:
- `ID` - Unique identifier in the format `pkg/path.SymbolName` or `pkg/path.Type.MethodName`
- `Name` - Simple symbol name
- `Package` - Package import path
- `Kind` - Category: "func", "type", "var", "const"
- `File` - Absolute path to the file defining this symbol
- `Pos` - Precise token.Position for error reporting

**DependencyGraph** - Core graph structure:
- `Symbols` - Map of symbol ID to Symbol object (all known symbols)
- `FileSyms` - Map of file path to list of symbol IDs defined in that file
- `OutEdges` - Map of symbol ID to the set of symbols it depends on (forward edges)
- `InEdges` - Map of symbol ID to the set of symbols that depend on it (reverse edges)

The bidirectional edge representation (both `OutEdges` and `InEdges`) allows efficient traversal in both directions:
- Forward: "What does this symbol depend on?" (for atomicity checking)
- Reverse: "What depends on this symbol?" (for impact analysis)

### Populating the Graph by Walking the AST

The graph construction follows a two-pass algorithm:

**Pass 1 - Register Definitions:**
1. Iterate through `pkg.TypesInfo.Defs` (all identifiers that define something)
2. Filter to package-level scope using `obj.Parent() == pkg.Types.Scope()`
3. Create Symbol objects with ID, name, package, kind, file, and position
4. Store in `Symbols` map and index in `FileSyms` map

**Pass 2 - Track Usages:**
1. Walk the AST of each file in the package
2. Find all function declarations (`*ast.FuncDecl`)
3. For each function, inspect the function body for symbol usages
4. Track both simple identifiers (`*ast.Ident`) and selector expressions (`*ast.SelectorExpr`)
5. Look up each identifier in `pkg.TypesInfo.Uses` to find the referenced object
6. If the referenced object is from another package or a different symbol in the same package, create a dependency edge

The implementation handles both package-level functions and methods. Methods are tracked with explicit receiver notation in the symbol ID (`pkg.Type.Method`) to distinguish them from package functions.

### Method Tracking Enhancement

The implementation includes explicit method tracking that goes beyond the original ADR design. When analyzing method declarations:

1. Extract the receiver type from the `*ast.FuncDecl.Recv` field
2. Construct method symbol IDs in the format `pkg.Type.Method`
3. Track method-to-method calls and method-to-function calls separately
4. This allows precise dependency tracking even when methods call other methods on the same or different types

## Transitive Dependency Analysis with Depth-First Search

The core validation requires transitive analysis: if staged function A calls unstaged function B which calls unstaged function C, all three dependencies must be flagged. A simple DFS traversal collects all reachable symbols from any starting point.

### Forward Dependency Traversal

`TransitiveDeps(startID)` performs a depth-first search starting from a given symbol ID:

1. Initialize a visited set and result list
2. Define a recursive DFS function that:
   - Marks the current symbol as visited
   - Adds it to the result list
   - Recursively visits all symbols in `OutEdges[id]` (symbols it depends on)
3. Return the complete list of transitive dependencies

This traversal is used during validation to find all symbols that a staged symbol depends on, either directly or indirectly.

### Reverse Dependency Traversal

`TransitiveDependents(targetID)` performs the reverse traversal using `InEdges`:

1. Same DFS approach as forward traversal
2. Instead of following `OutEdges`, follow `InEdges` (symbols that depend on the current symbol)
3. Returns all symbols that would be affected if the target symbol changed

While reverse traversal is not used in the current validation logic, it's valuable for future enhancements like impact analysis.

For the atomic commit check, the validator traverses from each symbol defined in staged files and verifies all dependencies are either in staged files or cleanly committed.

## Git Integration for Detecting Staged versus Unstaged Changes

**Shelling out to git is used instead of go-git** because it's simpler, handles edge cases better, and avoids library dependency issues. The implementation uses three primary git commands for all necessary information.

### Git Commands Used

**Getting staged files:**
- Command: `git diff --cached --name-only --diff-filter=ACMR`
- Purpose: List all staged files (added, copied, modified, renamed)
- Filter excludes deleted files since we only care about files being committed
- Returns list of relative file paths

**Detecting unstaged modifications:**
- Command: `git diff --name-only`
- Purpose: List all files with unstaged changes in the working tree
- Captures modifications not yet staged for commit
- Returns list of relative file paths

**Complete file status using porcelain format:**
- Command: `git status --porcelain -z`
- Purpose: Get complete status of all files in the repository
- Uses null-byte separators (`-z`) for proper handling of filenames with spaces
- Returns two-character status codes for each file

The porcelain format uses two-character status codes:
- First character: staging area status
- Second character: working tree status

Common status codes:
- `M ` - Modified and fully staged (ready to commit)
- `MM` - Modified with both staged and unstaged changes (partially staged)
- `??` - Untracked file
- `M_` - Modified but unstaged
- `_M` - Modified in worktree only
- `A ` - Added to staging area

**Reading staged content (critical for partial staging):**
- Command: `git show :path`
- Purpose: Read the staged version of a file from the git index
- The `:path` syntax reads from the staging area, not the working directory
- Essential when files are partially staged—must analyze the staged version, not working tree version

### Directory-Level Handling

The implementation includes special handling for untracked directories:
- Git reports untracked directories as `dir/` with a trailing slash
- The validator includes logic to check if a file is under an untracked directory
- This ensures dependencies on files in entirely untracked directories are caught

### Path Handling Strategy

The implementation uses a sophisticated path handling approach:
1. Convert all file paths to absolute paths internally for consistency
2. Perform all analysis and comparisons using absolute paths
3. Convert back to relative paths for display to the user and when invoking git commands
4. This approach is more robust when working directory changes or when files are in subdirectories

## The Core Validation Algorithm

The validation combines dependency analysis with git status checking. The algorithm flows as follows:

1. **Convert to absolute paths** - Convert the working directory to an absolute path for consistent handling

2. **Get file statuses from git** - Call `GetAllFileStatus()` to retrieve porcelain format status for all files

3. **Categorize files into sets:**
   - `staged` - Files with changes in the staging area (first status character is not space and not `?`)
   - `notStagedSet` - Files with unstaged changes OR untracked files (second status character is not space OR first character is `?`)

4. **Filter to Go files only** - Focus validation on `.go` files, ignore other file types

5. **Build overlay for partially-staged files** - For files with status `MM` (both staged and unstaged changes), retrieve staged content via `git show :path` and populate `packages.Config.Overlay` so the loader analyzes what will actually be committed

6. **Load all packages in the repository** - Call `packages.Load()` with pattern `./...` and the overlay to load all packages with full type information

7. **Build the complete dependency graph** - Iterate through all loaded packages and call `AnalyzePackage()` on each to populate the graph

8. **Check each staged file for violations:**
   - Get all symbols defined in the staged file from `FileSyms` map
   - For each symbol, compute transitive dependencies using `TransitiveDeps()`
   - For each dependency, check if its defining file is:
     - NOT in the `staged` set AND
     - IS in the `notStagedSet`
   - If both conditions are true, record a violation

9. **Return violations** - Each violation captures the staged file, staged symbol, missing file, and missing symbol

### Violation Structure

Each violation records:
- `StagedFile` - Relative path to the file being committed that has the violation
- `StagedSymbol` - Symbol ID from the staged file (what's being added/changed)
- `MissingFile` - Relative path to the file with unstaged changes that's needed
- `MissingSymbol` - Symbol ID that's needed but not staged

### File Status Logic

The key insight in the validation logic is the definition of "not staged":
- A file is considered "not staged" if it has unstaged changes OR is entirely untracked
- This is captured by checking: worktree status is not space OR staging status is `?`
- Untracked directories are handled by checking if a file path falls under a `dir/` entry

## Generated Files (Protobuf, Mocks)

Generated files need special handling—they should be required if staged code depends on symbols they define. Detection uses both comment markers and filename patterns.

### Detection Mechanisms

**Comment markers** - Look for standard generation indicators in file comments:
- "Code generated" (standard Go generation marker)
- "DO NOT EDIT" (common in generated files)
- "generated by" (common prefix in generation tools)

**Filename patterns** - Common conventions for generated files:
- `.pb.go` - Protocol buffer generated code
- `.pb.gw.go` - gRPC gateway generated code
- `_mock.go` - Mock generated code
- `_gen.go` - Generic generated code
- `_string.go` - stringer generated code
- `zz_generated` - Kubernetes-style generated code

### Validation Behavior for Generated Files

The validation treats generated files identically to regular files in the dependency graph. This design decision ensures consistency and prevents incomplete commits:

**How generated files are handled:**

1. **Symbol extraction** - Generated files are analyzed like any other Go file; their symbols (types, functions, constants) are added to the dependency graph with their defining file paths tracked

2. **Dependency tracking** - When staged code imports or uses symbols from a generated file, dependency edges are created just like with regular files

3. **Atomicity enforcement** - If staged code depends on symbols from an unstaged generated file, it's flagged as a violation with the same severity as regular file dependencies

4. **No special exemptions** - Generated files are not automatically excluded or treated as "always available"—if the generator was re-run and produced new output, that output must be staged

**Practical implications:**

- **Protocol buffers**: If you modify a `.proto` file and stage code that uses the new protobuf types, you must also stage the regenerated `.pb.go` files
- **Mocks**: Updating a mock generator configuration requires staging the regenerated `_mock.go` files if staged tests depend on the new mock behavior
- **Code generation tools**: Any `go generate` output that defines symbols used by staged code must be included in the commit

**Why this approach:**

- **Correctness**: Ensures the commit is truly self-contained—reviewers and CI can check out the commit and build successfully
- **Consistency**: Prevents situations where staged code compiles locally (using unstaged generated files in the working tree) but fails on a clean checkout
- **Explicit tracking**: Forces developers to consciously decide whether generated code changes belong in the same commit as the code that triggered regeneration

This strict approach may initially seem overly cautious for generated files, but it prevents subtle bugs where staged code depends on unstaged API changes in generated files.

## Testing Strategy

The implementation includes comprehensive end-to-end testing with real git repositories and controlled dependency scenarios.

### E2E Test Infrastructure

Located in `internal/validator/validator_e2e_test.go` (1,148 lines), the test suite:
- Creates isolated temporary git repositories for each test
- Uses test fixtures from `testdata/project/` with controlled dependency relationships
- Tests complete workflows from git staging through validation
- Verifies both success cases (no violations) and failure cases (violations detected)

### Test Fixture Structure

The `testdata/project/` directory contains a complete Go project with intentional dependency chains:
- `main.go` → depends on `service.go`
- `service.go` → depends on `utils.go` and `types.go`
- `circular_a.go` ⇄ `circular_b.go` - circular dependency test case
- `calculator.go` - method dependency examples
- `helper/`, `models/` - subpackage dependency examples
- `go.mod` defining `example.com/testproject` module

### Test Coverage Areas

The E2E test suite covers:
- **No violations** - All dependent files staged together (atomic commit succeeds)
- **Direct dependencies** - Single-level dependency violation detection
- **Transitive dependencies** - Multi-hop dependency chain violation detection
- **Circular dependencies** - Handling of cyclic symbol dependencies
- **Type dependencies** - Dependencies via type/interface usage
- **Multiple violations** - Multiple independent violation chains in one commit
- **Untracked files** - Dependencies on entirely new untracked files
- **Partially staged files** - Files with both staged and unstaged changes

### Test Helpers

Key test infrastructure functions:
- `setupTestRepo()` - Creates isolated git repository with test project
- `modifyFile()` - Append content to trigger file changes in test repo
- `writeFileContent()` - Overwrite file with given content (for creating `MM` state)
- `stageFiles()` - Stage specific files in test repository
- `runGit()` - Execute git commands in test context
- `logTestPattern()` - Structured logging for test diagnostics

## Build and Deployment

### Build Process

The project uses a Makefile for standardized build operations:
- `make build` - Compiles binary to `bin/darna` (produces 7.1 MB executable)
- `make test` - Runs all tests with race detection and coverage reporting
- `make lint` - Runs golangci-lint with configured rules
- `make clean` - Removes build artifacts

### Dependencies

The implementation has minimal external dependencies:
- **Required:** `golang.org/x/tools/go/packages` - For Go package loading and type analysis
- **No go-git dependency** - All git operations use shell commands
- **No other runtime dependencies** - Purely standard library plus go/packages

### Hook Installation

For use as a git hook with GetHooky or similar hook managers:
1. Build the binary: `make build`
2. Install the hook: `hooky add pre-commit "./bin/darna"`
3. Verify: The tool will run on every `git commit`

The tool requires no configuration files—all behavior is based on git repository state and Go package analysis.

## Performance Considerations

### Current Implementation Approach

The current implementation loads all packages in the repository using the pattern `./...`. This provides complete coverage but can be slow for very large repositories with many packages.

**Performance characteristics:**
- First run: Cold package loading, type checking entire codebase (slower)
- Subsequent runs: Go's build cache helps, but still re-analyzes all packages
- Scale: Noticeable on repositories with >100 packages

### Potential Optimizations (Not Currently Implemented)

The following optimizations could significantly improve performance for large repositories:

#### 1. Selective Package Loading

**Current limitation**: Loading `./...` analyzes the entire codebase on every run, even when only a few files are staged.

**Optimization approach**:
- Build package patterns dynamically based on staged files: `file=/path/to/staged/file.go`
- Use `packages.Load()` with these targeted patterns instead of `./...`
- The packages API automatically loads transitive dependencies, so the dependency graph will still be complete

**Implementation considerations**:
- Must handle the case where a staged file's package imports symbols from packages that aren't directly staged
- Need to ensure cross-package dependencies are still fully captured
- Edge case: A staged file in package A uses symbols from package B, which uses symbols from unstaged package C—all three packages must be loaded

**Expected performance gain**:
- For repositories with >100 packages where only 1-3 files are staged: **5-10x faster**
- Diminishing returns when many packages are affected by the staged changes

**Implementation complexity**: Low (20-30 lines of code change in the package loading logic)

#### 2. Dependency Graph Caching

**Current limitation**: Every run rebuilds the entire dependency graph from scratch, even when most of the codebase hasn't changed.

**Optimization approach**:
- After building the graph, serialize it to `~/.cache/darna/<repo-hash>/graph.gob`
- On subsequent runs, load the cached graph and incrementally update only packages containing changes (staged or unstaged)
- Use git to track file modification times: `git diff --name-only HEAD` to find all changed files since last commit

**Implementation considerations**:
- **Cache invalidation**: When `go.mod` changes, invalidate entire cache (dependencies may have changed)
- **Staleness detection**: Compare cached graph's build time against file modification times
- **Incremental updates**: Remove symbols from changed files, re-analyze those files, update dependency edges
- **Disk space**: Graph for a medium-sized project (~50 packages) is typically <1 MB serialized

**Expected performance gain**:
- First run: No change (must build graph)
- Subsequent runs with no changes: **50-100x faster** (load from disk, skip analysis)
- Subsequent runs with small changes: **10-20x faster** (incremental update)

**Implementation complexity**: Medium (100-150 lines for serialization, cache management, and incremental updates)

**Cache structure**:
- Store graph serialized with `encoding/gob`
- Key the cache by repository root path hash + current git HEAD commit
- Automatically expire caches older than 7 days

#### 3. Parallel Package Analysis

**Current limitation**: Packages are analyzed sequentially in the order returned by `packages.Load()`.

**Optimization approach**:
- After loading packages, analyze them in parallel using goroutines
- Use a worker pool to limit concurrency (e.g., `GOMAXPROCS` workers)
- Aggregate results into the dependency graph with mutex protection

**Implementation considerations**:
- Package loading itself is already parallelized by the `go/packages` API
- The bottleneck is AST walking and symbol extraction
- Need thread-safe graph updates when multiple goroutines call `AnalyzePackage()`

**Expected performance gain**:
- On machines with 8+ cores: **2-4x faster** for large codebases
- Diminishing returns on machines with fewer cores or smaller codebases

**Implementation complexity**: Medium (50-75 lines for worker pool and synchronization)

### Why Optimizations Are Deferred

The straightforward `./...` approach was chosen for the initial implementation because:

- **Simplicity**: Fewer moving parts, easier to debug, less code to maintain
- **Correctness**: Complete coverage guarantees no missed dependencies or edge cases
- **Good enough performance**: For repositories with <100 packages, pre-commit overhead is typically <2 seconds
- **Defer until needed**: Optimizing prematurely adds complexity without proven ROI

**When to implement**:
- **Selective loading**: When pre-commit time exceeds 5 seconds for small changesets in large repositories
- **Graph caching**: When developers run multiple commits per hour and pre-commit overhead becomes noticeable
- **Parallel analysis**: When profiling shows package analysis (not package loading) is the bottleneck

The recommended implementation order is: selective loading first (highest ROI for least complexity), then caching, then parallelization if still needed.

## Actual Implementation Metrics

The completed implementation consists of:

| Component | Lines of Code | File |
|-----------|---------------|------|
| **Git integration** | ~85 lines | `internal/git/git.go` |
| **Package analyzer** | ~100 lines | `internal/analyzer/analyzer.go` |
| **Dependency graph** | ~180 lines | `internal/graph/graph.go` |
| **Validator core** | ~135 lines | `internal/validator/validator.go` |
| **CLI interface** | ~75 lines | `cmd/darna/main.go` |
| **Unit tests** | ~400 lines | Various `*_test.go` files |
| **E2E tests** | 1,148 lines | `internal/validator/validator_e2e_test.go` |
| **Test fixtures** | ~300 lines | `internal/validator/testdata/project/` |
| **Total** | ~2,324 lines | Entire codebase |

The implementation is lean and focused, with comprehensive test coverage (1,548 lines of tests for 775 lines of production code).

## Key Implementation Details

### Symbol ID Format

The implementation uses two formats for symbol identification:

**Package-level functions:**
- Format: `github.com/user/repo/pkg.FunctionName`
- Example: `github.com/darccio/darna/internal/analyzer.LoadPackages`

**Methods (with receiver):**
- Format: `github.com/user/repo/pkg.Type.MethodName`
- Example: `github.com/darccio/darna/internal/graph.DependencyGraph.AnalyzePackage`

This distinction allows precise tracking of method calls vs. function calls in the dependency graph.

### Path Handling Flow

1. **Input:** User provides working directory (defaults to current directory)
2. **Conversion:** Convert to absolute path using `filepath.Abs()`
3. **Analysis:** All internal operations use absolute paths for file comparisons
4. **Git interaction:** Convert to relative paths when needed for git commands
5. **Display:** Convert to relative paths for user-facing violation messages

This approach ensures consistency even when working directory changes or when analyzing files in subdirectories.

### File Status Determination

**A file is considered "staged" if:**
- Its staging area status (first character in porcelain format) is not space
- AND it's not an untracked file (first character is not `?`)

**A file is considered "not staged" if:**
- Its worktree status (second character) is not space (has unstaged changes)
- OR it's entirely untracked (first character is `?`)
- OR it's a file under an untracked directory (`dir/` entry)

This logic correctly handles:
- Fully staged files (`M ` - ready to commit)
- Partially staged files (`MM` - both staged and unstaged changes)
- Unstaged modifications (`_M` - not yet staged)
- Untracked files (`??` - not in git at all)

### Partial Staging Support

When a file has both staged and unstaged changes (status `MM`), the validator uses `packages.Config.Overlay` to feed the staged content to the Go package loader instead of the working tree version. This ensures analysis reflects exactly what will be committed.

**How it works**:
1. After file categorization, iterate over all file statuses
2. For files where both staging and worktree status indicate changes (`MM`), retrieve the staged content via `git show :path`
3. Build an overlay map (`map[string][]byte`) keyed by absolute file path
4. Pass the overlay to `LoadPackages`, which sets `packages.Config.Overlay`
5. The go/packages loader uses overlay content instead of reading from disk for those files

**Why this matters**: Developers commonly stage one logical change, then immediately start working on the next feature. Without the overlay, the validator would analyze the working tree version and produce false positives when unstaged changes remove or modify symbols that the staged version still contains.

If `git show :path` fails for any file, the overlay entry is skipped and the validator falls back to analyzing the working tree version (preserving previous behavior).

## Summary

The atomic commit validator successfully implements the ADR's core recommendations:

**Architectural alignment:**
- Uses `golang.org/x/tools/go/packages` for type-aware analysis ✓
- Shells out to git commands for maximum reliability ✓
- Builds bidirectional dependency graph with DFS traversal ✓
- Provides clear violation messages with actionable suggestions ✓
- Integrates seamlessly with git hooks via exit codes ✓

**Implementation enhancements beyond ADR:**
- Explicit method tracking with receiver notation for precision
- Robust path handling (absolute internally, relative for display)
- Directory-level untracked file handling
- Sophisticated file status representation (staging area vs worktree)
- Partial staging support via `packages.Config.Overlay` (eliminates false positives for `MM` files)
- Comprehensive E2E test suite with test coverage

**Documented enhancement paths:**
- **Selective package loading** using `file=path` patterns (5-10x faster for large repos, ~20-30 LOC)
- **Dependency graph caching** with incremental updates (10-100x faster on subsequent runs, ~100-150 LOC)
- **Parallel package analysis** with worker pools (2-4x faster on multi-core machines, ~50-75 LOC)

The tool's simplicity comes from leveraging Go's type system—`types.Object.Pkg()` tells you exactly where every referenced symbol is defined, eliminating the need for manual import resolution or complex AST matching. The result is a focused, maintainable implementation with comprehensive test coverage.
